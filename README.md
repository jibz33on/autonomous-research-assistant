# ğŸ”¬ Autonomous Research Assistant

An AI-powered research tool that autonomously plans, executes, and synthesizes comprehensive research reports on any topic.

## ğŸ“– Description

The Autonomous Research Assistant uses cutting-edge AI technologies to conduct end-to-end research autonomously. It breaks down complex topics into subtopics, searches the web for relevant information, and synthesizes findings into a comprehensive report with citations.

## ğŸ¯ Use Cases

- **Academic Research**: Quickly gather information on research topics
- **Market Analysis**: Understand industry trends and competitive landscapes
- **Learning & Education**: Deep-dive into new subjects efficiently
- **Content Creation**: Research background information for articles or reports
- **Decision Making**: Gather insights for informed business decisions

## ğŸŒ Scope

**What it does:**
- Autonomously plans research strategy by identifying key subtopics
- Executes web searches and collects relevant documents
- Synthesizes information into structured reports with citations
- Answers follow-up questions using collected research (RAG-powered)

**What it doesn't do:**
- Real-time data analysis or live monitoring
- Access to paywalled or authenticated content
- Generate original research or conduct experiments

## ğŸ—ï¸ Architecture

![Architecture Diagram]
(./assets/architecture-diagram.png)

The system follows a layered architecture with 6 layers:
```
Layer 0: Foundation
â”œâ”€â”€ Configuration management (config.py)
â””â”€â”€ Logging utilities (logging.py)

Layer 1: LLM
â”œâ”€â”€ OpenAI client wrapper (client.py)
â””â”€â”€ System prompts (prompts.py)

Layer 2: Tools
â”œâ”€â”€ Web search (websearch.py) - Tavily API
â”œâ”€â”€ Web scraper (scraper.py) - BeautifulSoup
â””â”€â”€ Document parser (parser.py) - Text chunking

Layer 3: RAG (Retrieval-Augmented Generation)
â”œâ”€â”€ Embeddings (embeddings.py) - OpenAI text-embedding-3-small
â”œâ”€â”€ Vector store (vector_store.py) - ChromaDB
â””â”€â”€ Retriever (retriever.py) - Semantic search

Layer 4: Agents
â”œâ”€â”€ Planner Agent - Creates research plan
â”œâ”€â”€ Executor Agent - Collects documents
â””â”€â”€ Synthesizer Agent - Generates report + Q&A

Layer 5: Graph (LangGraph Workflow)
â”œâ”€â”€ State definition (state.py)
â”œâ”€â”€ Node functions (nodes.py)
â””â”€â”€ Workflow orchestration (workflow.py)

Layer 6: Application
â””â”€â”€ Streamlit UI (app.py)
```

**Workflow:**
```
User Input â†’ Planner Agent â†’ Executor Agent â†’ Synthesizer Agent â†’ Report + Q&A
              (subtopics)      (documents)       (RAG synthesis)
```

## ğŸ› ï¸ Tech Stack

- **LLM**: GPT-4o-mini (OpenAI)
- **Orchestration**: LangGraph
- **Web Search**: Tavily API
- **Web Scraping**: BeautifulSoup4, Requests
- **RAG**: ChromaDB (vector store) + OpenAI Embeddings
- **Framework**: Streamlit
- **Language**: Python 3.11

## ğŸ“¦ Installation

### Prerequisites
- Python 3.11+
- OpenAI API key
- Tavily API key

### Setup

1. **Clone the repository**
```bash
git clone <repository-url>
cd autonomous-research-assistant
```

2. **Create conda environment**
```bash
conda create -n autonomous-research-assistant python=3.11 -y
conda activate autonomous-research-assistant
```

3. **Install dependencies**
```bash
pip install -r requirements.txt --break-system-packages
```

4. **Configure API keys**

Create a `.env` file in the project root:
```env
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
```

5. **Run the application**
```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

## ğŸš€ Usage

1. Enter your research topic in the text input
2. Click "Start Research" button
3. Watch the AI autonomously research the topic
4. View the comprehensive report with citations
5. Ask follow-up questions for deeper insights

## ğŸ“ Project Structure
```
autonomous-research-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/          # AI agents (planner, executor, synthesizer)
â”‚   â”œâ”€â”€ graph/           # LangGraph workflow
â”‚   â”œâ”€â”€ llm/             # LLM client and prompts
â”‚   â”œâ”€â”€ rag/             # RAG system (embeddings, vector store, retriever)
â”‚   â”œâ”€â”€ tools/           # Tools (search, scraper, parser)
â”‚   â””â”€â”€ utils/           # Utilities (config, logging)
â”œâ”€â”€ tests/               # Test files
â”œâ”€â”€ data/                # Data storage (ChromaDB)
â”œâ”€â”€ app.py               # Streamlit application
â”œâ”€â”€ .env                 # API keys (not in repo)
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md
```

## ğŸ‘¤ Author

Built by **Jibin Kunjumon**

---

*ğŸš€ Autonomous Research â€¢ ğŸ§  AI-Powered â€¢ ğŸ“š RAG-Enhanced*